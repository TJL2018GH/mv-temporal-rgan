** Workflow changes

*** Model extension to RCGAN
***** TODO add custom image shapes and prepare code to shift away from square images
***** TODO modify lfw for rcgan with artificially generated labels from other classifiers
***** TODO update final RGAN run on faces with all required changes (denser activations and re-normalization)
***** read on more innovative semi-supervised gan architectures that we could also use
***** publish separate annotated lfw-crop dataset, or consider using CIFAR-10 with reduced dataset size
***** changing to CIFAR might require modified descriptions and stuff
***** how to make results better? perhaps make deeper, but focus should not be on images
***** bottom horizontal artifact keeps showing, investigate origin and how to circumvent
***** consider changing RCGAN name to RACGAN
***** before publication, run models on simple data to get best results and publish models used
***** replace discriminator with existing supervised network to see how that can work better
***** modify model and run next iterations of R(AC)GAN
***** make efficient pipeline to update documentation and logging

*** Model stabilization and abstraction
***** TODO work on more efficient (automated) hard model memory handling (saving only one instance of weights in comb.h5 and abstracting via layer numbers) -> necessary for github clones to be light
***** TODO export optimizer weights as h5 instead of pickle for data consistency and compactness
***** TODO make modular function for model restoration, edit readme with new continue training details afterwards
***** TODO consider borrowing model architecture from other successful models and employ within local biomedical task
***** work on introspection tasks, where data is passed through layers step-wise and results are manually/automatically checked for explainability
***** port code to tensorflow2 for better integration -> might solve problem with accuracy printing based on non-binary target labels
***** consider that performance on images is not paramount, abstraction to medical data and construction of local evaluation techniques is more important
***** consider developing online per-epoch similarity checks, MMD and TRTS to check quality of samples
***** look up ganhacks for further possible improvements such as adding leaky-relu everywhere, and read on successful/innovative gan architectures
***** make pipeline variable/adaptable/scalable to higher (possibly non-square) dimensional data in case of 64 dimensional lfw faces (user more variables in models instead of hard-coding)
***** read papers for strategies/uses of synthetic data

*** Model visualization and presentation
***** TODO add extra option to ignore pics/gifs when cloning unless prompted
***** add function to generate best samples from trained model aside from already generated images
***** change matplotlib backend default back to instant working version when necessary

*** Model extension to biomedical time series
***** visualize data from MIMIC-III github repository in 2-dimensions to see smoothness or roughness
***** use ETH model on MIMIC-III and compare evaluations with own model
***** apply RCGAN technique towards this process and verify results with existing models through TSTR/TRTS and MMD checks

*** Heuristics
***** TODO add convergent pathway polynomial fit to check whether training is diverging or converging in given time frame
***** add gradient checks for logging and change vis.py to include colour on loss line for gradients
***** use tensorboard to analyze learning process
***** develop similarity/quality metrics which could be used alongside training

*** Possible architecture improvements
***** use Wasserstein loss with standard or improved training
***** use feature matching and minibatch discrimination to prevent mode collapse
***** consider adding Gaussian noise to images for stability (mixed outcomes predicted)
***** consider resnet architecture for certain skip-connections, could be linked to multi-scale gradient structure

*** Miscellaneous
***** models appear more stable when discriminator is significantly less powerful than generator
***** models are better when same noisy labels are used for both generator and discriminator
***** track how many epochs or batch runs needed to converge and try to optimize this (~500/2000 for mnist/lfw respectively)
***** add conditions to "train.py" to add separate pipeline in RCGAN training
***** add MIMIC-III 2d projection depiction and learning as gif on initial readme
***** remove caveats in readme once relevant developments are complete

*** High-level ideas
**** GAN stabilisation:
***** Gaussian label smoothing
***** differing learning rates for optimizers
***** Gaussian noise addition to images
***** spectral normalization
***** multi-scale gradient
**** Evaluation pipeline
***** use MIMIC data/models for direct MMD + TSTR/TRTS validations
***** explore privacy perspective and whether GAN is able to remove personal traits
***** or consider another architecture which can perform this function
**** Networks and higher-dimensions abstraction
***** extend to deeper model which can handle 64 pixels faces to check if abstraction possible
***** extend to RCGAN with realistic conditionings for actual usable data genration
**** Input images and feature masking
***** come up with mask to simulate missing data in real-life
***** compare input and output images as time series with signals
**** Documentation and code-health:
***** fix unused imports and sort with python tools
***** make detailed documentation and model visualizations
